大家好，这期视频给大家介绍yolo目标识别原理与环境准备，方便大家开展后续工作   

YOLO（You Only Look Once）是一种基于深度学习的实时目标检测算法，   
其核心思想是将目标检测问题转化为一个回归问题，   
通过单次前向传播即可完成目标定位和分类   

yolo的整体思想是，将输入图像划分为一个S*S的网格（例如分成4*4的网格）   
每个网格负责检测中心点落在该网格内的目标。每个网格会预测边界框和类别概率

边界框：
每个网格预测B个边界框，每个边界框包含5个值：
x,y,w,h,confidence
x和y是边界框的相对于网格的偏移量的中心坐标
w和h表示边界框的宽度和高度。这个高度是相对于整个图像的比例。
confidence是置信度，表示边界框内是否包含目标以及预测的准确性

类别概率
每个网格还会预测C个类别的概率
其中C是数据集中类别的总数
这里我们只有车牌识别一个类

在预测完成后，YOLO会输出一个S*S*（B*5+C）的张量

Yolo使用一个卷积神经网络CNN来提取图像特征并直接预测边界框和类别概率。
Yolo的损失函数由3部分组成：边界框坐标损失、置信度损失、类别损失

边界框坐标损失：计算预测边界框的中心坐标（x,y）和宽高（w,h）与真实值的误差
置信度损失：计算预测的置信度与真实值的误差。
类别损失：计算预测的类别概率与真实类别的误差。

损失函数的设计使得 YOLO 能够同时优化目标定位和分类任务。
对于我们这个项目，只有车牌一类，所以不需要分类。

YOLO会生成多个边界框，其中可能存在重叠的框。为了去除冗余的框，YOLO 使用非极大值抑制（NMS）
YOLO会根据置信度分数对边界框进行排序。
选择置信度最高的框，并移除与其重叠度(交并比)（IoU）超过一定阈值的其他框。
重复上述过程，直到所有框都被处理。

class 边界框
{
    float confidence;
};
vector<边界框> eraseBox(vector<边界框> boxes)
{
    eraseBox(vector<边界框> boxes);
}
void yolo_main()
{
    vector<边界框> boxes;
    boxes.sort_around_confidence();
    float iou_threshold=0.5;
    for(;;)
    {
        if(caluIOU(boxes[1],boxes[i]) > iou_threshold)
            boxes.erase(i);
    }
}
void yolo_main()
{
    vector<边界框> boxes;
    boxes.sort_around_confidence();
    float iou_threshold=0.5;
    vector<边界框> final=eraseBox(boxes);
}
这里给大家展示的只是伪代码，在使用yolo过程中我们并不需要详细理解具体是怎么实现的
如果大家对此感兴趣，可以在github上寻找yolo源代码进行学习




接下来介绍环境准备
首先我们需要一块Milk-V Duo开发板
同时我们需要PC主机的Linux环境，建议Ubuntu22.04系统
然后在Linux系统下配置Anaconda和Pycharm环境
然后配置PyTorch深度学习框架
上述的所有版本使用最新版即可。
具体的安装过程我们在下一期为大家展示