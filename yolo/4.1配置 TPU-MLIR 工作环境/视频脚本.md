下面我们配置 TPU-MLIR 工作环境，并使用校准表生成 INT8 对称模型
出于网络原因，这里的每一步都比前面我们做的要困难许多
同时因为我的计算机已经完成后面的任务，而且有的任务并不能跟着做，否则会造成不可逆的影响
所以这里再展示的同时会加上比较多的解释

配置TPU_MLIR环境有python3.10的强制要求

但是ubuntu大多数情况下系统对python版本有依赖，我们不能直接大幅度的更改
除了前面的虚拟环境，这里我们使用docker
tpu-mlir也给我们提供了docker镜像，会很方便我们完成任务

首先选择我们的工作目录，这里我选择在/home/tpu_mlir
这里我创建一个类似名称的文件夹作为展示，实际使用时请关注我的终端路径



下面安装docker
首先卸载可能的旧版本docker
输入如下命令
```bash
for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done
sudo apt autoremove
```
卸载完成后正式安装docker
输入如下命令
```bash
sudo apt update
sudo apt install apt-transport-https ca-certificates curl software-properties-common
sudo -i
curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/trusted.gpg.d/docker-ce.gpg
logout
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository "deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io
```
安装完成后，我们配置一下docker的镜像源，这样安装环境能快一点
我们首先需要看/etc/docker/daemon.json文件和其目录路径是否是完整的，如果不完整，我们需要创建该目录下的文件
```bash
sudo mkdir -p /etc/docker
sudo vim /etc/docker/daemon.json
```
确保文件存在后，编辑文件，添加镜像源
```json
{
  "registry-mirrors":[
    "https://yxzrazem.mirror.aliyuncs.com",
    "https://registry.docker-cn.com",
    "https://docker.mirrors.ustc.edu.cn",
    "https://hub-mirror.c.163.com",
    "https://mirror.baidubce.com",
    "https://2a6bf1988cb6428c877f723ec7530dbc.mirror.swr.myhuaweicloud.com",
    "https://docker.m.daocloud.io",
    "https://your_preferred_mirror",
    "https://dockerhub.icu",
    "https://docker.registry.cyou",
    "https://docker-cf.registry.cyou",
    "https://dockercf.jsdelivr.fyi",
    "https://docker.jsdelivr.fyi",
    "https://dockertest.jsdelivr.fyi",
    "https://mirror.aliyuncs.com",
    "https://dockerproxy.com",
    "https://docker.m.daocloud.io",
    "https://docker.nju.edu.cn",
    "https://docker.mirrors.sjtug.sjtu.edu.cn",
    "https://docker.mirrors.ustc.edu.cn",
    "https://mirror.iscas.ac.cn",
    "https://docker.rainbond.cc",
    "https://y3qevhs5.mirror.aliyuncs.com"
  ]
}
```
文件的内容会提供在评论区置顶和简介中，大家有需要可以进行获取
在编辑完成后，我们更新一下环境
```bash
sudo systemctl daemon-reload
sudo systemctl restart docker
```
然后运行测试，测试的内容是docker的hello-world
如果输出“Hello from Docker!”则表示Docker已经成功安装
```bash
sudo docker run hello-world
```
运行的时候会提示本地没有hello-world的镜像，docker会从镜像源中进行下载，这里大家稍作等待即可，因为我们已经配置好了镜像源

运行完成hello-world后，我们可以看一下有哪些镜像
```bash
sudo docker images
```
然后我们配置一下用户组，配置完成后就不用再sudo了
```bash
sudo usermod -aG docker ${USER}  # 这里可以将${USER}替换成指定的用户名，如sudo usermod -aG docker lizzy,且建议后者
su - lizzy      # 刷新shell
docker images   # 验证
```
最后，我们拉取tpuc的镜像
```  bash
# 拉取镜像
docker pull sophgo/tpuc_dev:v3.2
# 新建容器
# 注意修改<myname>的值
# docker run --privileged --name <myname> -v $PWD:/workspace -it sophgo/tpuc_dev:v3.2
# 这里我是
docker run --privileged --name yolo -v $PWD:/workspace -it sophgo/tpuc_dev:v3.2
docker run --privileged --name yolo_test -v $PWD:/workspace -it sophgo/tpuc_dev:v3.2
```
这一步之后，我们就会进入docker的workspace
```bash
root@d9e9aac2c4d7:/workspace# 
```
现在就已经进入docker了。我们退出docker重新进入一下
```bash
exit
docker ps -a
# 找到我们刚刚创建的容器，看他的两个参数，然后重新启动
docker exec -it yolo /bin/bash
```



下面安装tpu_mlir
在docker下，运行命令
```  bash
root@d9e9aac2c4d7:/workspace# pip install tpu_mlir
root@d9e9aac2c4d7:/workspace# pip install tpu_mlir[onnx]
```
下载模型转换工具包，将包拉取到Workspace目录下后，运行脚本
```bash
root@d9e9aac2c4d7:/workspace# git clone https://github.com/milkv-duo/tpu-mlir.git
root@d9e9aac2c4d7:/workspace# source ./tpu-mlir/envsetup.sh
```


安装完成后，开始onnx模型的编译和转换
我们前面已经获得了yolo11n的onnx模型
现在也获得了模型转换工具包
接下来，在docker的workspace目录下再创建目录model_yolo11n
我们将把需要的相关内容放到这个文件夹下进行处理
```bash
root@d9e9aac2c4d7:/workspace# mkdir model_yolo11n
root@d9e9aac2c4d7:/workspace# cp -rf yolo11n.onnx ./model_yolo11n
root@d9e9aac2c4d7:/workspace# cp -rf tpu-mlir/regression/image ./model_yolo11n
root@d9e9aac2c4d7:/workspace# cp -rf tpu-mlir/regression/dataset/COCO2017 ./model_yolo11n
root@d9e9aac2c4d7:/workspace# cd model_yolo11n
root@d9e9aac2c4d7:/workspace/model_yolo11n# ls
```
这时应该有三个返回值COCO2017   image   yolo11n.onnx
现在我们就可以开始进行onnx模型的转换，生成int8对称模型了
这里的命令比较长和耗时，大家需要耐心等待
首先是将onnx模型转换成mlir模型
使用如下命令
```bash
model_transform \
    --model_name yolo11n \
    --model_def ../yolo11n.onnx \
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb \
    --test_input ../image/dog.jpg \
    --test_result yolo11n_top_outputs.npz \
    --mlir yolo11n.mlir
```
```bash
model_transform.py \
--model_name yolo11n \
--model_def yolo11n.onnx \
--input_shapes [[1,3,640,640]] \
--mean 0.0,0.0,0.0 \
--scale 0.0039216,0.0039216,0.0039216 \
--keep_aspect_ratio \
--pixel_format rgb \
--test_input ../image/dog.jpg \
--test_result yolo11n_top_outputs.npz \
--mlir yolo11s.mlir
```
完成之后，我们会使用校准表生成INT8对称模型
```bash
root@d9e9aac2c4d7:/workspace/model_yolo11n/workspace# 
run_calibration yolo11n.mlir \
    --dataset ../COCO2017 \
    --input_num 100 \
    -o yolo11n_cali_table
```
运行完成后会生成名为 yolo11n_cali_table 的文件，通过ls命令查看
最后将模型转成INT8对称量化模型
```bash
root@d9e9aac2c4d7:/workspace/model_yolov5s/workspace# 
model_deploy \
    --mlir yolo11n.mlir \
    --quantize INT8 \
    --calibration_table yolo11n_cali_table \
    --processor cv180x \
    --test_input yolo11n_in_f32.npz \
    --test_reference yolo11n_top_outputs.npz \
    --tolerance 0.85,0.45 \
    --model yolo11n_cv180x_int8_sym.cvimodel
```
这里的参数非常多，我们一个一个进行解释
对参数的解释很重要，因为命令中很多使用的是相对路径
在第一个命令中
--model_name yolo115n
含义： 指定转换后的模型名称为yolo11n。
作用： 这个名称会用于输出文件和日志中，方便识别。
--model_def yolov5n.onnx
含义： 指定原始模型的定义文件，这里是yolov5s.onnx。
作用： 输入的ONNX模型文件，model_transform.py会基于这个文件进行模型转换。
--input_shapes [[1,3,640,640]]
含义： 指定模型的输入形状，这里是一个4D张量，形状为[1, 3, 640, 640]。
作用： 明确模型的输入维度，有助于在转换过程中正确设置输入层的形状。
--mean 0.0,0.0,0.0
含义： 指定输入数据的均值，对每个通道的均值都设置为0.0。
作用： 在预处理时，对输入数据进行均值减法操作，常用于数据标准化。
--scale 0.0039216,0.0039216,0.0039216
含义： 指定输入数据的缩放因子，对每个通道的缩放因子都设置为0.0039216。
作用： 在预处理时，对输入数据进行缩放操作。0.0039216等价于1/255，通常用于将像素值从[0,255]归一化到[0,1]。
--keep_aspect_ratio
含义： 指定在预处理时保持图像的长宽比。
作用： 当输入图像的尺寸与模型输入尺寸不一致时，通过填充（padding）而不是拉伸（stretching）来调整尺寸，以保持原始图像的长宽比。
--pixel_format rgb
含义： 指定输入图像的像素格式，这里为rgb。
作用： 告诉预处理程序输入图像是RGB格式，如果模型需要BGR格式，需要进行相应的通道顺序调整。
--test_input ./dog.jpg
含义： 指定用于测试的输入图像文件，这里是./dog.jpg。
作用： 在转换过程中，使用该图像进行一次前向推理，验证转换是否成功，并生成中间输出结果。
--test_result yolov5n_top_outputs.npz
含义： 指定测试结果的输出文件，这里是yolov5s_top_outputs.npz。
作用： 将测试推理的输出结果保存到该文件中，方便后续分析和验证。
--mlir yolov5n.mlir
含义： 指定输出的MLIR文件名，这里是yolov5s.mlir。
作用：model_transform.py会将ONNX模型转换为MLIR格式的模型文件，供后续编译和优化使用。





run_calibration.py yolov5n.mlir
含义： 运行run_calibration.py脚本，对yolov5n.mlir模型进行校准（calibration）。
作用：yolov5n.mlir是之前通过model_transform.py转换得到的MLIR格式的模型文件。校准过程用于为模型的量化（quantization）生成校准表，从而在模型推理时实现更高的效率和更小的模型大小。
--dataset COCO2017
含义： 指定用于校准的数据集，这里是COCO2017。
作用： 校准过程需要一批代表性的输入数据来统计模型中各层的激活值分布，从而确定量化参数。COCO2017是一个广泛使用的目标检测数据集，包含了各种图像，可以提供多样化的输入。
--input_num 100
含义： 指定用于校准的输入数据数量，这里是100张图像。
作用： 校准过程并不需要整个数据集的所有图像，通常使用一定数量的图像即可达到较好的效果。100张图像可以在校准精度和速度之间取得平衡。
-o yolov5s_cali_table
含义： 指定校准结果输出的校准表文件名，这里是yolov5s_cali_table。
作用： 校准表包含了模型中各层的量化参数（如scale和zero point），在后续的量化过程中需要使用该校准表对模型进行量化。










--mlir yolov5n.mlir
含义： 指定输入的 MLIR 格式模型文件，这里是 yolov5n.mlir。
作用： 提供要部署的模型，该模型已经通过 model_transform.py 从原始格式（如 ONNX）转换为 MLIR 格式。
--quant_input
含义： 指定对模型的输入进行量化。
作用： 将模型的输入数据从浮点数转换为量化的整数格式（如 INT8），以减少计算量和内存占用。
--quant_output
含义： 指定对模型的输出进行量化。
作用： 将模型的输出数据也量化为整数格式，确保输入和输出的一致性，并提高整体性能。
--quantize INT8
含义： 指定模型的量化位宽，这里是 8 位整数（INT8）。
作用： 将模型的权重和激活值从浮点数转换为 8 位整数，以降低模型大小和加速推理。
--calibration_table yolov5n_cali_table
含义： 指定用于量化的校准表文件，这里是 yolov5n_cali_table。
作用： 校准表包含了模型中各层的量化参数（如 scale 和 zero point），这些参数是通过校准过程生成的，用于在量化时保持模型精度。
--processor cv180x
含义： 指定目标处理器，这里是 CVITEK 的 CV180X 芯片。
作用： 根据目标硬件平台对模型进行优化，确保生成的模型能够在指定的处理器上高效运行。
--test_input yolov5n_in_f32.npz
含义： 指定用于测试的输入数据文件，这里是 yolov5n_in_f32.npz。
作用： 在部署过程中，使用该测试输入数据验证模型的正确性，确保量化后的模型输出与原始模型一致。
--test_reference yolov5s_top_outputs.npz
含义： 指定参考输出数据文件，这里是 yolov5s_top_outputs.npz。
作用： 包含原始模型的输出结果，用于与量化后模型的输出进行比较，评估量化对模型精度的影响。
--tolerance 0.85,0.45
含义： 指定模型输出比对的容差值，这里是两个值 0.85 和 0.45。
作用： 用于评估量化后模型的输出与参考输出的相似度，确保在可接受的精度范围内。
第一个值（0.85）： 表示相似度阈值，如余弦相似度，值越接近 1，表示越相似。
第二个值（0.45）： 表示可接受的误差范围，如均方误差（MSE）或平均绝对误差（MAE），值越小，误差越小。

--model yolov5n_cv181x_int8_sym.cvimodel
含义： 指定生成的模型文件名，这里是 yolov5n_cv180x_int8_sym.cvimodel。
作用： 将量化并针对目标处理器优化后的模型保存为指定文件，供部署在 CV180X 芯片的设备上使用。
yolov5n： 模型名称。
cv181x： 目标处理器型号。
int8： 量化位宽为 INT8。
sym： 表示使用对称量化。 到这里，我们便成功获得了自己模型的cvimodel版本。





